# -*- coding: utf-8 -*-
"""agri.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjYFScwa50fgeM5IWhxj6yPAMTJUAr68
"""

import pandas as pd
import ipywidgets as widgets
from IPython.display import display

# Step 1: Load and verify the dataset structure
try:
    data = pd.read_csv('agri.csv', delimiter=',', header=0)

    # Inspect and fix column issues
    if len(data.columns) == 1:  # Single-column issue due to incorrect parsing
        data = data[data.columns[0]].str.split(',', expand=True)
        data.columns = ['state', 'district', 'market', 'commodity', 'arrival_date',
                        'min_price', 'max_price', 'modal_price', 'extra_col_1', 'extra_col_2']

    print("File loaded successfully! Columns:", data.columns)

    # Ensure numeric conversion for price columns
    for col in ['min_price', 'max_price', 'modal_price']:
        data[col] = pd.to_numeric(data[col], errors='coerce')

    # Extract unique values for dropdowns
    unique_states = sorted(data['state'].dropna().unique())
    unique_districts = sorted(data['district'].dropna().unique())
    unique_commodities = sorted(data['commodity'].dropna().unique())

except FileNotFoundError:
    print("Error: The file 'agri.csv' was not found. Ensure it's in the correct path!")
    raise

except KeyError as e:
    print(f"Missing expected column: {e}. Verify your dataset's structure.")
    raise

# Step 2: Create interactive widgets
commodity_dropdown = widgets.Dropdown(
    options=unique_commodities,
    description='Commodity:',
)

state_dropdown = widgets.Dropdown(
    options=unique_states,
    description='State:',
)

district_dropdown = widgets.Dropdown(
    options=unique_districts,
    description='District:',
)

output_step1 = widgets.Output()
output_step2 = widgets.Output()
output_step3 = widgets.Output()

# Step 3: Functions for interactivity
# Function to display top 3 prices for a selected commodity
def display_top_prices(change):
    with output_step1:
        output_step1.clear_output()
        selected_commodity = commodity_dropdown.value
        filtered_data = data[data['commodity'] == selected_commodity]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        top_prices = filtered_data.nlargest(3, 'modal_price')
        if top_prices.empty:
            print(f"No data found for commodity '{selected_commodity}'.")
        else:
            display(top_prices[['state', 'market', 'modal_price']])

commodity_dropdown.observe(display_top_prices, names='value')

# Function to display state-level data
def display_state_data(change):
    with output_step2:
        output_step2.clear_output()
        selected_state = state_dropdown.value
        selected_commodity = commodity_dropdown.value
        filtered_data = data[
            (data['state'] == selected_state) & (data['commodity'] == selected_commodity)
        ]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        sorted_data = filtered_data.sort_values('modal_price', ascending=False)
        if sorted_data.empty:
            print(f"No data found for state '{selected_state}' and commodity '{selected_commodity}'.")
        else:
            display(sorted_data[['market', 'modal_price']])

state_dropdown.observe(display_state_data, names='value')

# Function to display district-level data
def display_district_data(change):
    with output_step3:
        output_step3.clear_output()
        selected_district = district_dropdown.value
        selected_commodity = commodity_dropdown.value
        filtered_data = data[
            (data['district'] == selected_district) & (data['commodity'] == selected_commodity)
        ]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        sorted_data = filtered_data.sort_values('modal_price', ascending=False)
        if sorted_data.empty:
            print(f"No data found for district '{selected_district}' and commodity '{selected_commodity}'.")
        else:
            display(sorted_data[['market', 'modal_price']])

district_dropdown.observe(display_district_data, names='value')

# Step 4: Display widgets
display(commodity_dropdown, output_step1)
display(state_dropdown, output_step2)
display(district_dropdown, output_step3)

import pandas as pd
import ipywidgets as widgets
from IPython.display import display

# Step 1: Load and verify the dataset structure
try:
    data = pd.read_csv('agri.csv', delimiter=',', header=0)

    # Inspect and fix column issues
    if len(data.columns) == 1:  # Single-column issue due to incorrect parsing
        data = data[data.columns[0]].str.split(',', expand=True)
        data.columns = ['state', 'district', 'market', 'commodity', 'arrival_date',
                        'min_price', 'max_price', 'modal_price', 'extra_col_1', 'extra_col_2']

    print("File loaded successfully! Columns:", data.columns)

    # Ensure numeric conversion for price columns
    for col in ['min_price', 'max_price', 'modal_price']:
        data[col] = pd.to_numeric(data[col], errors='coerce')

    # Extract unique values for dropdowns
    unique_states = sorted(data['state'].dropna().unique())
    unique_districts = sorted(data['district'].dropna().unique())
    unique_commodities = sorted(data['commodity'].dropna().unique())

except FileNotFoundError:
    print("Error: The file 'agri.csv' was not found. Ensure it's in the correct path!")
    raise

except KeyError as e:
    print(f"Missing expected column: {e}. Verify your dataset's structure.")
    raise

# Step 2: Create interactive widgets
commodity_dropdown = widgets.Dropdown(
    options=unique_commodities,
    description='Commodity:',
)

state_dropdown = widgets.Dropdown(
    options=unique_states,
    description='State:',
)

district_dropdown = widgets.Dropdown(
    options=unique_districts,
    description='District:',
)

output_step1 = widgets.Output()
output_step2 = widgets.Output()
output_step3 = widgets.Output()

# Function to display top 3 prices for a selected commodity
def display_top_prices(change):
    with output_step1:
        output_step1.clear_output()
        selected_commodity = commodity_dropdown.value
        filtered_data = data[data['commodity'] == selected_commodity]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        top_prices = filtered_data.nlargest(3, 'modal_price')
        if top_prices.empty:
            print(f"No data found for commodity '{selected_commodity}'.")
        else:
            display(top_prices[['state', 'market', 'modal_price']])

commodity_dropdown.observe(display_top_prices, names='value')

# Function to display state-level data with all rows visible
def display_state_data(change):
    with output_step2:
        output_step2.clear_output()
        selected_state = state_dropdown.value
        selected_commodity = commodity_dropdown.value
        filtered_data = data[
            (data['state'] == selected_state) & (data['commodity'] == selected_commodity)
        ]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        sorted_data = filtered_data.sort_values('modal_price', ascending=False)

        if sorted_data.empty:
            print(f"No data found for state '{selected_state}' and commodity '{selected_commodity}'.")
        else:
            # Set Pandas option to display all rows
            pd.set_option('display.max_rows', None)
            display(sorted_data[['market', 'modal_price']])
            # Reset Pandas display option to default (for other outputs)
            pd.reset_option('display.max_rows')

state_dropdown.observe(display_state_data, names='value')

# Function to display district-level data
def display_district_data(change):
    with output_step3:
        output_step3.clear_output()
        selected_district = district_dropdown.value
        selected_commodity = commodity_dropdown.value
        filtered_data = data[
            (data['district'] == selected_district) & (data['commodity'] == selected_commodity)
        ]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        sorted_data = filtered_data.sort_values('modal_price', ascending=False)
        if sorted_data.empty:
            print(f"No data found for district '{selected_district}' and commodity '{selected_commodity}'.")
        else:
            display(sorted_data[['market', 'modal_price']])

district_dropdown.observe(display_district_data, names='value')

# Step 4: Display widgets
display(commodity_dropdown, output_step1)
display(state_dropdown, output_step2)
display(district_dropdown, output_step3)

import pandas as pd
import ipywidgets as widgets
from IPython.display import display

# -------------------------------
# Step 1: Load and verify the dataset structure
# -------------------------------
try:
    # Load the CSV with the correct delimiter. If the file is not parsed properly,
    # check if itâ€™s loading as a single column.
    data = pd.read_csv('/content/agri.csv', delimiter=',', header=0)

    # If it seems that the data is loaded into a single column (due to delimiter issues),
    # split that column and assign headers manually.
    if len(data.columns) == 1:
        data = data[data.columns[0]].str.split(',', expand=True)
        data.columns = ['state', 'district', 'market', 'commodity', 'arrival_date',
                        'min_price', 'max_price', 'modal_price', 'extra_col_1', 'extra_col_2']

    print("File loaded successfully! Columns:", data.columns)

    # Convert price columns to numeric; invalid entries become NaN
    for col in ['min_price', 'max_price', 'modal_price']:
        data[col] = pd.to_numeric(data[col], errors='coerce')

    # Extract and sort unique values for creating the dropdown options;
    # drop any NaN values to ensure valid options.
    unique_states = sorted(data['state'].dropna().unique())
    unique_districts = sorted(data['district'].dropna().unique())
    unique_commodities = sorted(data['commodity'].dropna().unique())

except FileNotFoundError:
    print("Error: The file 'agri.csv' was not found. Ensure it's in the correct path!")
    raise

except KeyError as e:
    print(f"Missing expected column: {e}. Verify your dataset's structure.")
    raise

# -------------------------------
# Step 2: Create interactive widgets
# -------------------------------
commodity_dropdown = widgets.Dropdown(
    options=unique_commodities,
    description='Commodity:',
)

state_dropdown = widgets.Dropdown(
    options=unique_states,
    description='State:',
)

district_dropdown = widgets.Dropdown(
    options=unique_districts,
    description='District:',
)

# Output areas for each step:
output_step1 = widgets.Output()  # For top 3 commodity prices across India
output_step2 = widgets.Output()  # For aggregated top market per district in the state
output_step3 = widgets.Output()  # For detailed district-level market prices

# -------------------------------
# Step 3: Define interactive functions
# -------------------------------

# Function to display the top 3 prices for the selected commodity across India.
def display_top_prices(change):
    with output_step1:
        output_step1.clear_output()
        selected_commodity = commodity_dropdown.value
        filtered_data = data[data['commodity'] == selected_commodity]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        top_prices = filtered_data.nlargest(3, 'modal_price')
        if top_prices.empty:
            print(f"No data found for commodity '{selected_commodity}'.")
        else:
            display(top_prices[['state', 'market', 'modal_price']])

commodity_dropdown.observe(display_top_prices, names='value')

# Function to display state-level data â€“ for each district in the selected state,
# only the top market (with the highest modal_price) is shown.
def display_state_data(change):
    with output_step2:
        output_step2.clear_output()
        selected_state = state_dropdown.value
        selected_commodity = commodity_dropdown.value
        filtered_data = data[(data['state'] == selected_state) & (data['commodity'] == selected_commodity)]
        filtered_data = filtered_data.dropna(subset=['modal_price'])

        if filtered_data.empty:
            print(f"No data found for state '{selected_state}' and commodity '{selected_commodity}'.")
        else:
            # Group by district and for each group, take the row with the highest modal_price
            aggregated = filtered_data.loc[filtered_data.groupby('district')['modal_price'].idxmax()]
            aggregated = aggregated.sort_values('modal_price', ascending=False)
            # Show all rows without truncation
            pd.set_option('display.max_rows', None)
            display(aggregated[['district', 'market', 'modal_price']])
            pd.reset_option('display.max_rows')

state_dropdown.observe(display_state_data, names='value')

# Function to display detailed district-level data:
# When a district is selected, show all markets in that district for the selected commodity,
# sorted in descending order of modal_price.
def display_district_data(change):
    with output_step3:
        output_step3.clear_output()
        selected_district = district_dropdown.value
        selected_commodity = commodity_dropdown.value
        filtered_data = data[(data['district'] == selected_district) & (data['commodity'] == selected_commodity)]
        filtered_data = filtered_data.dropna(subset=['modal_price'])
        sorted_data = filtered_data.sort_values('modal_price', ascending=False)
        if sorted_data.empty:
            print(f"No data found for district '{selected_district}' and commodity '{selected_commodity}'.")
        else:
            display(sorted_data[['market', 'modal_price']])

district_dropdown.observe(display_district_data, names='value')

# -------------------------------
# Step 4: Display the widgets
# -------------------------------
display(commodity_dropdown, output_step1)
display(state_dropdown, output_step2)
display(district_dropdown, output_step3)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sys

# For LSTM
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# =============================================================================
# 1. User Inputs
# =============================================================================
state_input = input("Enter the state: ")
district_input = input("Enter the district: ")
commodity_input = input("Enter the commodity: ")
future_year = int(input("Enter the future year (e.g., 2100): "))

# =============================================================================
# 2. Load and Filter agri.csv in Chunks (Memory-friendly)
# =============================================================================
# We use only necessary columns.
agri_cols = ['state', 'district', 'commodity', 'arrival_date', 'modal_price']
dtypes = {'state': 'category', 'district': 'category', 'commodity': 'category'}

agg_chunks = []
chunk_size = 100000

print("Reading agri.csv in chunks and filtering for the given parameters...")
try:
    for chunk in pd.read_csv("agri.csv", usecols=agri_cols, dtype=dtypes, chunksize=chunk_size):
        mask = ((chunk['state'] == state_input) &
                (chunk['district'] == district_input) &
                (chunk['commodity'] == commodity_input))
        filtered = chunk.loc[mask]
        if not filtered.empty:
            agg_chunks.append(filtered)
except Exception as e:
    print("Error reading agri.csv:", e)
    sys.exit()

if len(agg_chunks) == 0:
    print("No matching data found in agri.csv for the specified filters.")
    sys.exit()

df_agri_filtered = pd.concat(agg_chunks, ignore_index=True)
df_agri_filtered['arrival_date'] = pd.to_datetime(df_agri_filtered['arrival_date'],
                                                    format='%d/%m/%Y',
                                                    errors='coerce')
df_agri_filtered['year'] = df_agri_filtered['arrival_date'].dt.year

# =============================================================================
# 3. Aggregate Data by Year
# =============================================================================
# Aggregate modal_price by year (using mean) for modeling.
df_agg = df_agri_filtered.groupby('year')['modal_price'].mean().reset_index()

# =============================================================================
# 4. Load Climate Data and Merge (Using Only Numeric Columns)
# =============================================================================
try:
    df_climate = pd.read_csv("climate.csv")
except Exception as e:
    print("Error reading climate.csv:", e)
    sys.exit()

df_climate_state = df_climate[df_climate['state'] == state_input]
if df_climate_state.empty:
    print("No climate data found for state:", state_input)
    sys.exit()

# Select only numeric columns (ignoring nonnumeric ones)
numeric_climate = df_climate_state.select_dtypes(include=[np.number])
if numeric_climate.empty:
    print("No numeric climate features found for state:", state_input)
    sys.exit()
state_climate_features = numeric_climate.iloc[0].values.astype(float)
climate_features = numeric_climate.columns.tolist()

# Append numeric climate features as constant columns to our yearly aggregated data.
for feat in climate_features:
    df_agg[feat] = float(df_climate_state.iloc[0][feat])

cols = ['year', 'modal_price'] + climate_features
df_agg = df_agg[cols]

print("Aggregated Data Sample:")
print(df_agg.head())

# =============================================================================
# 5. Prepare Data for LSTM Modeling
# =============================================================================
data_raw = df_agg.values  # shape: (n_years, num_features)

scaler_X = MinMaxScaler()
data_scaled = scaler_X.fit_transform(data_raw)

scaler_y = MinMaxScaler()
y_raw = df_agg['modal_price'].values.reshape(-1, 1)
y_scaled = scaler_y.fit_transform(y_raw)

look_back = 3

def create_sequences(data, target, look_back):
    X_seq, y_seq = [], []
    for i in range(len(data) - look_back):
        X_seq.append(data[i:i+look_back])
        y_seq.append(target[i+look_back])
    return np.array(X_seq), np.array(y_seq)

X_seq, y_seq = create_sequences(data_scaled, y_scaled, look_back)

if len(X_seq) == 0:
    print("Not enough data to create sequences. At least {} records are required.".format(look_back + 1))
    sys.exit()

print("Shape of LSTM input sequences:", X_seq.shape)

# =============================================================================
# 6. Build and Train the LSTM Model
# =============================================================================
num_features = data_scaled.shape[1]

model = Sequential([
    Input(shape=(look_back, num_features)),
    LSTM(50, activation='relu'),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse')

print("\nTraining LSTM model...")
model.fit(X_seq, y_seq, epochs=50, verbose=1)

# =============================================================================
# 7. Forecast Future Modal Price using Iterative Prediction
# =============================================================================
last_year = int(df_agg['year'].max())
n_future = future_year - last_year

if n_future <= 0:
    print("Future year must be greater than the last historical year (", last_year, ")")
    sys.exit()

current_seq = data_scaled[-look_back:].copy()  # shape: (look_back, num_features)

predicted_years = []
predicted_modal_prices = []

print("\nPredicting future modal prices...")
for i in range(n_future):
    pred_scaled = model.predict(current_seq[np.newaxis, :])
    pred_modal_raw = scaler_y.inverse_transform(pred_scaled)[0, 0]

    new_year = last_year + i + 1
    predicted_years.append(new_year)
    predicted_modal_prices.append(pred_modal_raw)

    new_row_raw = np.concatenate(([new_year, pred_modal_raw], state_climate_features))
    new_row_scaled = scaler_X.transform(new_row_raw.reshape(1, -1))[0]

    current_seq = np.vstack([current_seq[1:], new_row_scaled])

# =============================================================================
# 8. Plotting the Outputs (Four Graphs)
# =============================================================================

# Graph 1: Price Prediction Plot with Annotation for the particular year
historical_years = df_agg['year'].values
historical_modal_prices = df_agg['modal_price'].values

plt.figure(figsize=(12, 5))
plt.plot(historical_years, historical_modal_prices, marker='o', label='Historical Modal Price')
plt.plot(predicted_years, predicted_modal_prices, marker='x', linestyle='--', color='red', label='Predicted Modal Price')

# Annotate the predicted value for the input future year (last element)
pred_val = predicted_modal_prices[-1]
plt.annotate(f"{future_year}: {pred_val:.2f}",
             xy=(future_year, pred_val),
             xytext=(10, -15),
             textcoords='offset points',
             arrowprops=dict(arrowstyle="->", color='black'))

plt.xlabel('Year')
plt.ylabel('Modal Price')
plt.title(f'Modal Price Prediction for {commodity_input} in {district_input}, {state_input}')
plt.legend()
plt.show()

# Graph 2: Climate Features Bar Chart
plt.figure(figsize=(8, 5))
plt.bar(climate_features, state_climate_features, color='skyblue')
plt.xlabel('Climate Feature')
plt.ylabel('Value')
plt.title(f'Climate Features for {state_input}')
plt.show()

# Graph 3: Combined Graph of Price and One Climate Feature
selected_climate_feature = climate_features[0]
combined_years = np.concatenate([historical_years, predicted_years])
selected_value = state_climate_features[climate_features.index(selected_climate_feature)]
climate_line = np.full(combined_years.shape, selected_value)

fig, ax1 = plt.subplots(figsize=(12, 5))
color = 'tab:blue'
ax1.set_xlabel('Year')
ax1.set_ylabel('Modal Price', color=color)
ax1.plot(historical_years, historical_modal_prices, marker='o', color=color, label='Historical Modal Price')
ax1.plot(predicted_years, predicted_modal_prices, marker='x', linestyle='--', color='tab:red', label='Predicted Modal Price')
ax1.tick_params(axis='y', labelcolor=color)

# Annotate the future year prediction on this graph too.
ax1.annotate(f"{future_year}: {predicted_modal_prices[-1]:.2f}",
             xy=(future_year, predicted_modal_prices[-1]),
             xytext=(10, -15),
             textcoords='offset points',
             arrowprops=dict(arrowstyle="->", color='black'))

ax2 = ax1.twinx()
color = 'tab:green'
ax2.set_ylabel(selected_climate_feature, color=color)
ax2.plot(combined_years, climate_line, linestyle=':', color=color, label=selected_climate_feature)
ax2.tick_params(axis='y', labelcolor=color)

fig.tight_layout()
fig.suptitle('Combined Plot: Price Prediction & Climate Feature', y=1.05)
fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))
plt.show()

# Graph 4: Heatmap of Correlations (Price & Climate Features)
plt.figure(figsize=(10, 8))
correlation = df_agg.corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap: Modal Price & Climate Features')
plt.show()

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# Streamlit App Title
st.title("ðŸŒ¾ Agricultural Modal Price Forecast")
st.markdown("Predict future modal prices for a commodity using LSTM with climate data")

# Input Section
state_input = st.text_input("Enter the State", value="Karnataka")
district_input = st.text_input("Enter the District", value="Belgaum")
commodity_input = st.text_input("Enter the Commodity", value="Tomato")
future_year = st.number_input("Enter the Future Year (e.g., 2030)", min_value=2024, max_value=2100, step=1)

# File Upload
agri_file = st.file_uploader("Upload agri.csv", type="csv")
climate_file = st.file_uploader("Upload climate.csv", type="csv")

if st.button("Run Forecast"):
    if not agri_file or not climate_file:
        st.error("Please upload both agri.csv and climate.csv files.")
        st.stop()

    # Step 1: Load and Filter agri.csv in Chunks
    agri_cols = ['state', 'district', 'commodity', 'arrival_date', 'modal_price']
    dtypes = {'state': 'category', 'district': 'category', 'commodity': 'category'}
    chunk_size = 100000
    agg_chunks = []

    for chunk in pd.read_csv(agri_file, usecols=agri_cols, dtype=dtypes, chunksize=chunk_size):
        mask = ((chunk['state'] == state_input) &
                (chunk['district'] == district_input) &
                (chunk['commodity'] == commodity_input))
        filtered = chunk.loc[mask]
        if not filtered.empty:
            agg_chunks.append(filtered)

    if len(agg_chunks) == 0:
        st.error("No matching data found in agri.csv for the specified filters.")
        st.stop()

    df_agri_filtered = pd.concat(agg_chunks, ignore_index=True)
    df_agri_filtered['arrival_date'] = pd.to_datetime(df_agri_filtered['arrival_date'], format='%d/%m/%Y', errors='coerce')
    df_agri_filtered['year'] = df_agri_filtered['arrival_date'].dt.year

    # Step 2: Aggregate Data by Year
    df_agg = df_agri_filtered.groupby('year')['modal_price'].mean().reset_index()

    # Step 3: Load and Process Climate Data
    df_climate = pd.read_csv(climate_file)
    df_climate_state = df_climate[df_climate['state'] == state_input]
    if df_climate_state.empty:
        st.error("No climate data found for state: " + state_input)
        st.stop()

    numeric_climate = df_climate_state.select_dtypes(include=[np.number])
    if numeric_climate.empty:
        st.error("No numeric climate features found for state: " + state_input)
        st.stop()

    state_climate_features = numeric_climate.iloc[0].values.astype(float)
    climate_features = numeric_climate.columns.tolist()

    for feat in climate_features:
        df_agg[feat] = float(df_climate_state.iloc[0][feat])

    cols = ['year', 'modal_price'] + climate_features
    df_agg = df_agg[cols]
    st.write("### Aggregated Data Sample")
    st.write(df_agg.head())

    # Step 4: Prepare Data for LSTM
    data_raw = df_agg.values
    scaler_X = MinMaxScaler()
    data_scaled = scaler_X.fit_transform(data_raw)
    scaler_y = MinMaxScaler()
    y_raw = df_agg['modal_price'].values.reshape(-1, 1)
    y_scaled = scaler_y.fit_transform(y_raw)

    look_back = 3
    def create_sequences(data, target, look_back):
        X_seq, y_seq = [], []
        for i in range(len(data) - look_back):
            X_seq.append(data[i:i+look_back])
            y_seq.append(target[i+look_back])
        return np.array(X_seq), np.array(y_seq)

    X_seq, y_seq = create_sequences(data_scaled, y_scaled, look_back)
    if len(X_seq) == 0:
        st.error(f"Not enough data to create sequences. At least {look_back + 1} records are required.")
        st.stop()

    # Step 5: Train LSTM Model
    num_features = data_scaled.shape[1]
    model = Sequential([
        Input(shape=(look_back, num_features)),
        LSTM(50, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X_seq, y_seq, epochs=50, verbose=0)

    # Step 6: Forecast
    last_year = int(df_agg['year'].max())
    n_future = future_year - last_year
    if n_future <= 0:
        st.error("Future year must be greater than last available year: " + str(last_year))
        st.stop()

    current_seq = data_scaled[-look_back:].copy()
    predicted_years = []
    predicted_modal_prices = []

    for i in range(n_future):
        pred_scaled = model.predict(current_seq[np.newaxis, :], verbose=0)
        pred_modal_raw = scaler_y.inverse_transform(pred_scaled)[0, 0]
        new_year = last_year + i + 1
        predicted_years.append(new_year)
        predicted_modal_prices.append(pred_modal_raw)

        new_row_raw = np.concatenate(([new_year, pred_modal_raw], state_climate_features))
        new_row_scaled = scaler_X.transform(new_row_raw.reshape(1, -1))[0]
        current_seq = np.vstack([current_seq[1:], new_row_scaled])

    # Step 7: Visualizations
    historical_years = df_agg['year'].values
    historical_modal_prices = df_agg['modal_price'].values

    # Graph 1: Modal Price Forecast
    fig1, ax1 = plt.subplots()
    ax1.plot(historical_years, historical_modal_prices, marker='o', label='Historical')
    ax1.plot(predicted_years, predicted_modal_prices, marker='x', linestyle='--', color='red', label='Forecasted')
    ax1.annotate(f"{future_year}: {predicted_modal_prices[-1]:.2f}",
                 xy=(future_year, predicted_modal_prices[-1]),
                 xytext=(10, -15), textcoords='offset points',
                 arrowprops=dict(arrowstyle="->"))
    ax1.set_xlabel("Year")
    ax1.set_ylabel("Modal Price")
    ax1.legend()
    st.pyplot(fig1)

    # Graph 2: Climate Bar Chart
    fig2, ax2 = plt.subplots()
    ax2.bar(climate_features, state_climate_features, color='skyblue')
    ax2.set_ylabel("Value")
    ax2.set_title(f"Climate Features for {state_input}")
    st.pyplot(fig2)

    # Graph 3: Combined Plot
    selected_climate_feature = climate_features[0]
    combined_years = np.concatenate([historical_years, predicted_years])
    selected_value = state_climate_features[climate_features.index(selected_climate_feature)]
    climate_line = np.full(combined_years.shape, selected_value)

    fig3, ax3 = plt.subplots()
    ax3.plot(historical_years, historical_modal_prices, label='Historical Price', color='tab:blue')
    ax3.plot(predicted_years, predicted_modal_prices, linestyle='--', label='Forecasted Price', color='tab:red')
    ax4 = ax3.twinx()
    ax4.plot(combined_years, climate_line, linestyle=':', color='tab:green', label=selected_climate_feature)
    fig3.tight_layout()
    st.pyplot(fig3)

    # Graph 4: Correlation Heatmap
    fig4, ax4 = plt.subplots()
    corr = df_agg.corr()
    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", ax=ax4)
    ax4.set_title("Correlation Heatmap")
    st.pyplot(fig4)

    # Final Output
    st.success(f"Predicted Modal Price in {future_year}: â‚¹{predicted_modal_prices[-1]:.2f}")